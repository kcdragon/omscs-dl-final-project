{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adversarial_images.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-crf6mG18NM",
        "outputId": "56c24ee0-fedc-4c4a-9096-ba887f4a82f6"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoVsSVp2JCA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image \n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "DIR = \"/content/drive/MyDrive/OMSCS/DL/FinalProject\"\n",
        "DATA_DIR = f'{DIR}/data'\n",
        "NAME = 'mnist'\n",
        "DATA_SET_CLASS = torchvision.datasets.MNIST\n",
        "image_size = 28\n",
        "in_channels = 1\n",
        "fgsm_alpha = 0.5\n",
        "fgsm_epsilon = 0.25\n",
        "\n",
        "sys.path.append(os.path.abspath(DIR))\n",
        "\n",
        "import team36\n",
        "from team36.mnist.vgg import VGG\n",
        "from team36.attacks.fast_gradient_attack_data_set import FastSignGradientAttackDataSet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j45tknOO2OBi"
      },
      "source": [
        "model = VGG(image_size=image_size, in_channels=in_channels)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "state_dict = torch.load(f\"{DIR}/checkpoints/{NAME}-vgg.pth\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuySINFE2quf"
      },
      "source": [
        "test_set = DATA_SET_CLASS(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())\n",
        "attack_test_set = FastSignGradientAttackDataSet(test_set, model, criterion, epsilon=fgsm_epsilon, device='cuda')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "QxpD5YwN2UtQ",
        "outputId": "e2f702b8-f321-4f88-e748-15594310b1a8"
      },
      "source": [
        "index = 1 # cifar10\n",
        "\n",
        "input, ground_truth = test_set[index]\n",
        "adversarial_input, _ = attack_test_set[index]\n",
        "\n",
        "display(transforms.functional.to_pil_image(input))\n",
        "display(transforms.functional.to_pil_image(adversarial_input))\n",
        "\n",
        "image_dir = f\"{DIR}/images\"\n",
        "\n",
        "pil_image = transforms.functional.to_pil_image(input)\n",
        "pil_image.save(f\"{image_dir}/{NAME}-{str(index)}.png\")\n",
        "\n",
        "pil_image = transforms.functional.to_pil_image(adversarial_input)\n",
        "pil_image.save(f\"{image_dir}/{NAME}-{str(index)}-{fgsm_epsilon}-fgsm-adversarial.png\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F24FECC3E90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpElEQVR4nE2Sv29PURjGP/fmYvkKE4tEokkXg0VE7mQTJJb2ual/oCQiqfIniBhQOwtNS++TVEK6dGNRNLVgaAcpXcRADEK1vYb3nO/XPXd47znveZ9fF4TiRUCqBIgydkAm9oyjNhWWZfITbUJYVORT/R49/Fn7VrHACFMhAuzQSdab9sfoR0iDKWRA+OpdmBp+cZydeSwjcJmAjpxo7xx493BjnR4WMblCGLjYTK1+m+Zxx4oxcVollstXHp0R1Eu0Co6orzrW+c3uxu7+J4XyEOFbk09P10ctLABKwgwDDO1qJrISY1eQIKy3x7j8RJBaEdlkGP/ZPTiYeABCJakNXd/bvvyaTgBwGXctPi23H9r/UgtfQ0/v5tzc8wQUSypJKUwP8aaNkQ6GOCGI2a7bn8pAklSAsMzfimv3gV/bYwvqnTMjM38KpaxnLwC0zavvizXQtOzMlylZVgBo+HK2bra3tiY3Z95TgZDF7bUxa+kezaVTI69ra+PZHgbE+9qU9agU8VtmSxUMhUwRdiVJKaoss+znheO2nZuUQQeFBg7+AzCxx2tmZPZyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F2511275B50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}