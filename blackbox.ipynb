{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924bc271-165a-4d74-8f7d-8434ad9991d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012a5ea-5e24-4d61-9eee-af0c7e928d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blackbox Attack\n",
    "\n",
    "The blackbox attack works as follows:\n",
    "Since we do not know details about the model we are attacking, we train a \"substitute model\" to approximate the \"target model\".\n",
    "This is done using a small sample of training data, labeled by the target model (aka the oracle) instead of using the true labels. \n",
    "This way, the substitute learns to mimic the target model.\n",
    "In addition, we augment this training data using \"Jacobian-based data augmentation\" (TODO)\n",
    "Finally, we use one of the regular attacks on the substitute model. Supposedly, an attack that works well against the substitute\n",
    "will also work well against the target. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f478a7-7dd8-4d49-a5ca-c213a8ca572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.autograd import grad\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import team36\n",
    "from team36.mnist.data_loading import MNIST_Loader\n",
    "from team36.mnist.vgg import VGG\n",
    "from team36.mnist.cnn import CNN\n",
    "from team36.attacks.fast_gradient_attack_data_set import FastSignGradientAttackDataSet\n",
    "from team36.training import train, validate, accuracy, predict, predict_from_loader, do_training, load_or_train, train_val_split, train_batch\n",
    "\n",
    "DIR = '.'\n",
    "DATA_DIR = f'{DIR}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557589a6-1c27-4fe2-aa10-dc4e790cd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1\n",
    "Train the target model (aka the Oracle) or load from a checkpoint\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8988865-ab3e-46b5-a23c-b4e20a2231ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkest\\miniconda3\\envs\\cs7643-final-project-cpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            )]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set up the datasets\n",
    "It is interesting to compare using the same dataset for the substitute and oracle vs. using different datasets\n",
    "\"\"\"\n",
    "ORACLE_DATASET = 'MNIST' # 'MNIST' or 'CIFAR10'\n",
    "SUB_DATASET = 'MNIST' \n",
    "DATASET_NAMES = [ORACLE_DATASET, SUB_DATASET]\n",
    "MODEL_NAMES = ['oracle', 'sub']\n",
    "ORACLE = 0\n",
    "SUB = 1\n",
    "datasets = [] # two-element list to store the oracle dataset and the substitute dataset\n",
    "dataset_image_sizes = []\n",
    "dataset_channels = []\n",
    "test_datasets = []\n",
    "\n",
    "# class Grayscale_to_RGB(object):\n",
    "#     def __call__(self, sample):\n",
    "#         print(sample)\n",
    "#         return sample\n",
    "\n",
    "# def grayscale_to_rgb(sample):\n",
    "#     print(sample)\n",
    "#     return sample\n",
    "# #     return sample.repeat(1, 3, 1, 1)\n",
    "\n",
    "for idx, dataset_name in enumerate(DATASET_NAMES):\n",
    "    transform_seq = [transforms.ToTensor()]\n",
    "    if dataset_name == 'MNIST':\n",
    "        image_size = 28\n",
    "        in_channels = 1\n",
    "        if idx == SUB and ORACLE_DATASET != 'MNIST': # if substitute uses mnist, but oracle uses other dataset add padding to match image size\n",
    "            padding = (dataset_image_sizes[ORACLE] - image_size) // 2\n",
    "            transform_seq.append(transforms.Pad(padding, fill=0))\n",
    "            image_size += padding * 2\n",
    "#             transform_seq.append(transforms.Lambda(lambda x: x))\n",
    "            transform_seq.append(transforms.Lambda(lambda x: x.repeat(3, 1, 1)))\n",
    "            in_channels = 3 # also need to copy to 3 channels to match rgb cifar\n",
    "            # NOTE: above assumes oracle_dataset has larger images and that there is an even number difference in the image sizes\n",
    "        dataset = torchvision.datasets.MNIST(root=DATA_DIR, train=True, download=True, \n",
    "                                              transform=transforms.Compose(transform_seq))\n",
    "        test_dataset = torchvision.datasets.MNIST(root=DATA_DIR, train=False, download=True, \n",
    "                                              transform=transforms.Compose(transform_seq))\n",
    "#         if idx == SUB and ORACLE_DATASET != 'MNIST':\n",
    "#             # also need to copy to image to 3 channels to match rgb cifar\n",
    "# #             transform_seq.append(grayscale_to_rgb) # copy single channel to 3 channels (from https://discuss.pytorch.org/t/grayscale-to-rgb-transform/18315)\n",
    "#             dataset.data = dataset.data.unsqueeze(1).repeat(1, 3, 1, 1)            \n",
    "#             in_channels = 3\n",
    "    elif dataset_name == 'CIFAR10':\n",
    "        image_size = 32\n",
    "        in_channels = 3\n",
    "        dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True,\n",
    "                                                transform=transforms.Compose(transform_seq))\n",
    "        test_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, \n",
    "                                              transform=transforms.Compose(transform_seq))\n",
    "    datasets.append(dataset)\n",
    "    dataset_image_sizes.append(image_size)\n",
    "    dataset_channels.append(in_channels)\n",
    "    test_datasets.append(test_dataset)\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a8a768-bb15-4d79-9677-4667566a2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_size = dataset_image_sizes[ORACLE]\n",
    "in_channels = dataset_channels[ORACLE]\n",
    "oracle = VGG(image_size=image_size, in_channels=in_channels) # set the target model here\n",
    "oracle_checkpoint = f'{DATASET_NAMES[ORACLE]}-vgg.pth' # e.g. 'MNIST-vgg.pth'\n",
    "# oracle_checkpoint = 'mnist-vgg.pth'\n",
    "oracle_checkpoint = oracle_checkpoint.lower()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "momentum = 5e-1\n",
    "# momentum = .9\n",
    "weight_decay = 1e-1\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "load_or_train(oracle, oracle_checkpoint, dataset=datasets[ORACLE], epochs=epochs, learning_rate=learning_rate, \n",
    "              weight_decay=weight_decay, momentum=momentum, batch_size=batch_size,\n",
    "             optim=torch.optim.SGD)\n",
    "# hyperparam tuning notes: \n",
    "# small learning rate is good for VGG on CIFAR (0.001 better than 0.01 and much better than 0.1)\n",
    "\n",
    "# if os.path.exists(oracle_checkpoint_path): # if trained checkpoint exists, load it\n",
    "#     state_dict = torch.load(f\"{DIR}/checkpoints/{checkpoint}\", map_location=torch.device('cpu'))\n",
    "#     model.load_state_dict(state_dict)\n",
    "# else: # else, train the model\n",
    "# training_indices, validation_indices, _, _ = train_test_split(\n",
    "#     range(len(target_data)),\n",
    "#     target_data.targets,\n",
    "#     stratify=target_data.targets,\n",
    "#     test_size=0.1,\n",
    "# )\n",
    "# oracle_train_split = torch.utils.data.Subset(target_data, training_indices)\n",
    "# oracle_val_split = torch.utils.data.Subset(target_data, validation_indices)\n",
    "# print(f\"{len(oracle_train_split)} in training set\")\n",
    "# print(f\"{len(oracle_val_split)} in validation set\")\n",
    "\n",
    "# do_training(oracle, training_split=oracle_train_split, validation_split=oracle_val_split, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f30d2-c77d-4b06-91d8-4d8e624bfb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2\n",
    "Train the substitute model on a small portion of the training data, using the oracle's predictions as the labels\n",
    "\n",
    "oracle pred full mnist\n",
    "replace targets\n",
    "train val split (small train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b9a9e09-4881-43de-b0ec-fe6ff1b8ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = CNN(image_size = dataset_image_sizes[SUB], in_channels = dataset_channels[SUB])\n",
    "sub_checkpoint = f'{DATASET_NAMES[SUB]}-substitute.pth' # e.g. 'MNIST-substitute.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4225531d-0182-438f-bdbe-cc3eef309f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(datasets[SUB], batch_size=100, shuffle=False, num_workers=0)\n",
    "# NOTE: due to a bug with lambda transforms on Windows, num_workers needs to be 0 or there will be an error\n",
    "# https://github.com/belskikh/kekas/issues/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aecbb988-e729-456f-9f7e-4e9f54770cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[SUB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ef9ad-a7e7-4fa6-8f7b-bb94e76613fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets[SUB].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e65fa-2ab1-44f5-ac0a-f077423a2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (data, target) in enumerate(loader):\n",
    "#         if torch.cuda.is_available():\n",
    "#             data = data.cuda()\n",
    "#             target = target.cuda()\n",
    "#         print(data.shape)\n",
    "# #         print(data.repeat(1, 3, 1, 1).shape)\n",
    "#         print(target)\n",
    "#         if idx > 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f52fece1-9a25-4957-a734-a03affe7e7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oracle_preds = predict_from_loader(oracle, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54401f17-407a-46cb-ba1a-7d6759d023c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_preds = oracle_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffd89050-b754-4560-8baf-9d4e1f2c11f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oracle_preds[oracle_preds != datasets[SUB].targets]) # check oracle preds mostly matches true labels (if oracle was trained on same dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e51dceb-0107-4646-9380-d3c3c6ad9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[SUB].targets = oracle_preds # replace true labels with oracle's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2efba5-15d2-4748-ad29-b7ac24381fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026dd5e-a83c-4944-a6ab-3e60fdd5436b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31861533-48c4-42a2-8d5f-b7331f471c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run either this cell (simple blackbox training) OR the next one (blackbox w/ jacobian-based data augmentation)\n",
    "epochs = 30\n",
    "train_size = 10000\n",
    "train = Subset(datasets[SUB], range(train_size))\n",
    "val = Subset(datasets[SUB], range(train_size, train_size*2)) # val split same size as train split\n",
    "load_or_train(sub, sub_checkpoint, train_split=train, val_split=val, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6ad07cd-f7d2-4690-86ac-baaa7a303aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "len X 150\n",
      "Epoch 0 | Training accuracy: 0.14000000059604645%\n",
      "Epoch 1 | Training accuracy: 0.2800000011920929%\n",
      "Epoch 2 | Training accuracy: 0.4466666579246521%\n",
      "Epoch 3 | Training accuracy: 0.6666666865348816%\n",
      "Epoch 4 | Training accuracy: 0.800000011920929%\n",
      "Epoch 5 | Training accuracy: 0.8600000143051147%\n",
      "Epoch 6 | Training accuracy: 0.8600000143051147%\n",
      "Epoch 7 | Training accuracy: 0.9133333563804626%\n",
      "Epoch 8 | Training accuracy: 0.9200000166893005%\n",
      "Epoch 9 | Training accuracy: 0.9200000166893005%\n",
      "Epoch 10 | Training accuracy: 0.9399999976158142%\n",
      "Epoch 11 | Training accuracy: 0.9399999976158142%\n",
      "Epoch 12 | Training accuracy: 0.9399999976158142%\n",
      "Epoch 13 | Training accuracy: 0.9733333587646484%\n",
      "Epoch 14 | Training accuracy: 0.9666666388511658%\n",
      "epoch 1\n",
      "len X 300\n",
      "Epoch 0 | Training accuracy: 0.09000000357627869%\n",
      "Epoch 1 | Training accuracy: 0.25999999046325684%\n",
      "Epoch 2 | Training accuracy: 0.4933333396911621%\n",
      "Epoch 3 | Training accuracy: 0.7633333206176758%\n",
      "Epoch 4 | Training accuracy: 0.753333330154419%\n",
      "Epoch 5 | Training accuracy: 0.8199999928474426%\n",
      "Epoch 6 | Training accuracy: 0.8700000047683716%\n",
      "Epoch 7 | Training accuracy: 0.8799999952316284%\n",
      "Epoch 8 | Training accuracy: 0.8999999761581421%\n",
      "Epoch 9 | Training accuracy: 0.9200000166893005%\n",
      "Epoch 10 | Training accuracy: 0.9200000166893005%\n",
      "Epoch 11 | Training accuracy: 0.9200000166893005%\n",
      "Epoch 12 | Training accuracy: 0.9300000071525574%\n",
      "Epoch 13 | Training accuracy: 0.9466666579246521%\n",
      "Epoch 14 | Training accuracy: 0.9566666483879089%\n",
      "epoch 2\n",
      "len X 600\n",
      "Epoch 0 | Training accuracy: 0.09833333641290665%\n",
      "Epoch 1 | Training accuracy: 0.2549999952316284%\n",
      "Epoch 2 | Training accuracy: 0.3616666793823242%\n",
      "Epoch 3 | Training accuracy: 0.5816666483879089%\n",
      "Epoch 4 | Training accuracy: 0.7616666555404663%\n",
      "Epoch 5 | Training accuracy: 0.8050000071525574%\n",
      "Epoch 6 | Training accuracy: 0.8050000071525574%\n",
      "Epoch 7 | Training accuracy: 0.8700000047683716%\n",
      "Epoch 8 | Training accuracy: 0.8933333158493042%\n",
      "Epoch 9 | Training accuracy: 0.8949999809265137%\n",
      "Epoch 10 | Training accuracy: 0.9116666913032532%\n",
      "Epoch 11 | Training accuracy: 0.9133333563804626%\n",
      "Epoch 12 | Training accuracy: 0.9183333516120911%\n",
      "Epoch 13 | Training accuracy: 0.9266666769981384%\n",
      "Epoch 14 | Training accuracy: 0.9316666722297668%\n",
      "epoch 3\n",
      "len X 1200\n",
      "Epoch 0 | Training accuracy: 0.14166666567325592%\n",
      "Epoch 1 | Training accuracy: 0.14666666090488434%\n",
      "Epoch 2 | Training accuracy: 0.4983333349227905%\n",
      "Epoch 3 | Training accuracy: 0.6833333373069763%\n",
      "Epoch 4 | Training accuracy: 0.7166666388511658%\n",
      "Epoch 5 | Training accuracy: 0.7608333230018616%\n",
      "Epoch 6 | Training accuracy: 0.8399999737739563%\n",
      "Epoch 7 | Training accuracy: 0.8708333373069763%\n",
      "Epoch 8 | Training accuracy: 0.871666669845581%\n",
      "Epoch 9 | Training accuracy: 0.8758333325386047%\n",
      "Epoch 10 | Training accuracy: 0.9058333039283752%\n",
      "Epoch 11 | Training accuracy: 0.9116666913032532%\n",
      "Epoch 12 | Training accuracy: 0.9125000238418579%\n",
      "Epoch 13 | Training accuracy: 0.9133333563804626%\n",
      "Epoch 14 | Training accuracy: 0.9200000166893005%\n",
      "epoch 4\n",
      "len X 2400\n",
      "Epoch 0 | Training accuracy: 0.0716666653752327%\n",
      "Epoch 1 | Training accuracy: 0.26249998807907104%\n",
      "Epoch 2 | Training accuracy: 0.31833332777023315%\n",
      "Epoch 3 | Training accuracy: 0.3929166793823242%\n",
      "Epoch 4 | Training accuracy: 0.5791666507720947%\n",
      "Epoch 5 | Training accuracy: 0.75%\n",
      "Epoch 6 | Training accuracy: 0.7983333468437195%\n",
      "Epoch 7 | Training accuracy: 0.7987499833106995%\n",
      "Epoch 8 | Training accuracy: 0.8087499737739563%\n",
      "Epoch 9 | Training accuracy: 0.8579166531562805%\n",
      "Epoch 10 | Training accuracy: 0.8737499713897705%\n",
      "Epoch 11 | Training accuracy: 0.8854166865348816%\n",
      "Epoch 12 | Training accuracy: 0.8895833492279053%\n",
      "Epoch 13 | Training accuracy: 0.8891666531562805%\n",
      "Epoch 14 | Training accuracy: 0.8929166793823242%\n",
      "epoch 5\n",
      "len X 4800\n",
      "Epoch 0 | Training accuracy: 0.052916668355464935%\n",
      "Epoch 1 | Training accuracy: 0.2318750023841858%\n",
      "Epoch 2 | Training accuracy: 0.5060416460037231%\n",
      "Epoch 3 | Training accuracy: 0.7416666746139526%\n",
      "Epoch 4 | Training accuracy: 0.7166666388511658%\n",
      "Epoch 5 | Training accuracy: 0.7325000166893005%\n",
      "Epoch 6 | Training accuracy: 0.8079166412353516%\n",
      "Epoch 7 | Training accuracy: 0.8214583396911621%\n",
      "Epoch 8 | Training accuracy: 0.8402083516120911%\n",
      "Epoch 9 | Training accuracy: 0.82833331823349%\n",
      "Epoch 10 | Training accuracy: 0.8402083516120911%\n",
      "Epoch 11 | Training accuracy: 0.8637499809265137%\n",
      "Epoch 12 | Training accuracy: 0.8725000023841858%\n",
      "Epoch 13 | Training accuracy: 0.87520831823349%\n",
      "Epoch 14 | Training accuracy: 0.8837500214576721%\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train with Jacobian-based data augmentation\n",
    "# here, training starts with a small sample from the training data\n",
    "# we train on this over some number of \"sub_epochs\"\n",
    "# then, we augment the data by adding the sign of the Jacobian times a constant (or just the Jacobian times a constant?)\n",
    "# repeat over some number of epochs\n",
    "epochs = 6\n",
    "sub_epochs = 15\n",
    "# train_size = 1000\n",
    "batch_size = 150\n",
    "step_size = 0.1\n",
    "learning_rate = 0.05\n",
    "momentum = 0.9\n",
    "# train = Subset(datasets[SUB], range(train_size))\n",
    "# val = Subset(datasets[SUB], range(train_size, train_size*2)) # val split same size as train split\n",
    "loader = torch.utils.data.DataLoader(test_datasets[SUB], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "batch_iter = iter(loader)\n",
    "X = batch_iter.next() # we just need one batch. result is: [[data], [targets]]\n",
    "for epoch in range(epochs):\n",
    "    sub = CNN(image_size = dataset_image_sizes[SUB], in_channels = dataset_channels[SUB]) # model is trained from scratch each time on the new augmented dataset\n",
    "    print('epoch', epoch)\n",
    "    print('len X', len(X[0]))\n",
    "#     train = Subset(datasets[SUB], range(epoch*batch_size, epoch*batch_size+batch_size))\n",
    "#     train = X\n",
    "#     print('training')\n",
    "    train_batch(X, sub, epochs=sub_epochs, learning_rate=learning_rate, momentum=momentum)\n",
    "#     print('done training')\n",
    "#     do_training(model, training_split=train, validation_split=train, epochs=sub_epochs) # train on batch \n",
    "    # generate the next batch using Jacobian data-augmentation\n",
    "#     print('augmentation')\n",
    "    X_size = len(X[0])\n",
    "    for i in range(X_size):\n",
    "        x = X[0][i] # X[0] gets data from batch, [i] gets the i'th data point\n",
    "        x = x.unsqueeze(0) # need to pass a batch to the Jacobian, so we make a one-element batch \n",
    "#         print('getting jacobian')\n",
    "        J = jacobian(sub, x)\n",
    "        J = J.squeeze(0).squeeze(1) # switch from batch Jacobian back to single\n",
    "#         print('getting label')\n",
    "        label = oracle_preds[epoch*batch_size + i]\n",
    "#         print('label', label)\n",
    "        J = J[label] # only need jacobian for the corresponding label\n",
    "#         print('got J for label')\n",
    "#         X[0][i] += J # modify the input using the Jacobian\n",
    "        J = torch.sign(J) # only want the sign of the Jacobian\n",
    "        # don't just modify the examples X; modify and concat with the original examples to get a larger training set\n",
    "#         print('modifying x')\n",
    "        new_x = X[0][i] + step_size * J\n",
    "        new_x = new_x.unsqueeze(0) # make into a batch so we can cat\n",
    "#         print('catting new x')\n",
    "        X[0] = torch.cat((X[0], new_x), 0)\n",
    "#         X[0][i] = X[0][i] + step_size * J \n",
    "#     print('making new preds')\n",
    "    new_preds = torch.argmax(oracle(X[0]), axis=1) # get predictions for augmented dataset\n",
    "#     new_preds = torch.argmax(oracle(X[0][epoch*batch_size:(epoch+1)*batch_size]), axis=1) # get predictions for the new batch\n",
    "#     new_preds = new_preds.unsqueeze(0)\n",
    "    X[1] = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa1b84e-b6b0-41fb-9861-4539a1855da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = torch.utils.data.DataLoader(datasets[SUB], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "# batch_iter = iter(loader)\n",
    "# X = batch_iter.next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd52828-0cd9-4884-af25-44c8a1c0a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.argmax(oracle(X[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f237f9b-9cc5-4075-aa71-4b5ae48b6ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.4169, -4.7919,  2.0163,  0.0857, -3.7622, -1.2417,  1.3576, -1.5906,\n",
       "          0.9843,  0.5568],\n",
       "        [-3.8718, -1.2136,  0.5668,  0.5602,  6.8551, -1.6826, -1.3260,  0.2603,\n",
       "         -0.6687,  2.3064]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle(X[0][1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5ff75-13e4-4170-bd9e-b6d7da00fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_iter = iter(loader)\n",
    "# X = batch_iter.next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddca46-5f9b-4456-afbb-a825748f4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3\n",
    "Generate attack data for the substitute model and test both models with it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f01ac1b-1aec-4121-b1d4-39c7788043de",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = oracle\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "models = [oracle]\n",
    "# models = [oracle, sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b302e607-115f-42d9-b4bf-011b997f6cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            )]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f9eef07-8bd1-437f-b78d-af44471b76c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle\n",
      "oracle Regular Test Accuracy is 0.9839000105857849\n",
      "oracle Regular Test Loss is 0.063465915620327\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Regular Test\"\"\"\n",
    "# test_set = torchvision.datasets.MNIST(root=DATA_DIR, train=False, download=True, \n",
    "#                                       transform=transforms.ToTensor())\n",
    "test_set = test_datasets[ORACLE] # since the substitute tries to mimic the oracle, we may as well test on the oracle's test set\n",
    "for model, name in zip(models, MODEL_NAMES):\n",
    "    print(name)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "    test_accuracy, _, test_loss = validate(None, test_loader, model, criterion)\n",
    "\n",
    "    print(f\"{name} Regular Test Accuracy is {test_accuracy}\")\n",
    "    print(f\"{name} Regular Test Loss is {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "697795cf-818f-469c-8174-3b87234f943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle\n",
      "oracle Attack Test Accuracy is 0.7071999907493591\n",
      "oracle Attack Test Loss is 0.8207333087921143\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Attack Test\"\"\"\n",
    "test_set = test_datasets[ORACLE] # since the substitute tries to mimic the oracle, we may as well test on the oracle's test set\n",
    "attack_test_set = FastSignGradientAttackDataSet(test_set, sub, criterion, epsilon=0.25)\n",
    "\n",
    "for model, name in zip(models, MODEL_NAMES):\n",
    "    print(name)\n",
    "    test_loader = torch.utils.data.DataLoader(attack_test_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "    test_accuracy, _, test_loss = validate(None, test_loader, model, criterion)\n",
    "\n",
    "    print(f\"{name} Attack Test Accuracy is {test_accuracy}\")\n",
    "    print(f\"{name} Attack Test Loss is {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba884cfd-8429-4ffb-af30-9b07a0cb4f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAWSUlEQVR4nO1daXcbt5Ktwo7euEh2Mv//l83MmeQltsSl2Y0dmA/dlGTHid0Upfd8Dq8dn2OHRPOyUEDtArjhhhtuuOGGG2644YYbbrjhhhtuuOGGG2644YYbbrjhhhtuuOGGNwe+yYJf/fGMcv7j/N91n3vF5RDJ9Ov8GxERAQBKKSWXkksuOeeccs7XZMKuuBYAFEIppYwyyhhljDFKCSGIAKXklFNKMcUUQwwhxHzNJ1+ZCCDlnAshuBBSCCk4Z5QQApBzijGEELz3znlrTYn/wRJBKoSUSimltNJaayk4Y5QA5BSCd95Za60ZzUBKCtcUyZWJMCGV1pWu6qqqmqqptBKcMQqQYnDOOGPGcRiGE4MU3FWffM3FgKuq0rVu6rqpm7pt2rrSUnBGAHL01o7GjMNp6HuBOXjrr/joaxFBAKBC6aqu6qqpm6ZpmrZpm6+JjKNWSnBakvcuXJHJVYgQQimjhEut67p6kkhTN7VWgk+vEYILJoSUUgrBIHnvAskll3IVnb8KEeRSKiWkqnRV61rXuq6rqqpUpaWkTy+TBBkTUkqlBSkxhmRiutZ9ch2J8Kpt20pXla4qPR1XWkklhOD0xeuYJFRIpXQlSQnBJ+JDiHCVw+sqRKhsNnebVVNXWmulpJRSSsE4YRTLS9uBFuRCSd1IzN77hMZCKfifIhHkut3+8nHbNbVSSkjBmeCMEgQsKT1ZQQgASCkvQgdegrUuFISS81XMpGsQEbpebT/814d1U0spOWeUUIqk5DRpQIECgEgIIUAoJSwlEuw4jC6VnGK8wkd4LREEKFTopltv7z983DSVnEUBUEqOIYaYUs6lACChlDLCBFLGIDdt252MjyF48u+XCBJCKdfV5m673WzWq0ZLTgAAIKWYQvDBz0wAkDDKOBVaF0pBqKppOxNicIwAACLBif4kv+Um/uskQoSUVd1uP/xyv121Ta2m5YpzznnvnHchxjgToYwJrpq2VZIRrup2dCl6YxAAgDBGEEpOOeeLHJXXEaGybrv1enP/8eOmrbWcV7On0zBYY613PoaUcgYgSCmXol5vQlt0prLqXMjRDSdSAIBwwRFyjDFedkG+bmsx2W7v77eb7d3dulFiXsz1+93+OAxmIhJnIoRyqdo7ExMgApO1C8kPmpMCAExqQSAF7wGgXHAkv4oI4bq7+/WX++161TWVZJPWhn7/+dPD43EYrXMh+phyAUBEymW1GkJBSlgBrioXxkoyggCEq0rTEj0jgHg+6d6NCBNVt/34Xx83XVMpyQgAQPHDcffpjz8+H/rRehdiCDMRIELWaw9McCJJBiqU0lIwggBM6LamJVpOiQ8x5bTUbnkNES513W3u7j9sGq0YI1ighGBOu8eHT39+2vej9T7EMEsEgHBZOyKrWlLNS0gFKaGUEhqprJqu4SVYw7nzPgQMCzfXpUSQIJVV3Xbdar3uasUpAUgxWDMcHz8/PDzu9qfRBh9jeH6Ts5HopmsksQKjN8aFlIHywqtmtelECdaOxllrrM0Ldf5SIoQxodvVqlu1TV1rSQAAohn643F/+Pzp8+P+OFgXXtIAgGhEf3isWNQcU7Tj0I8+IyeyW2/vNxKCt9b6oe+PmNKyD3QxEa50063X666ptRSzepweHx4e98fD4+PuOBgX/mJ+BDf2O1mMYpiit+PhaCJyUa/uPvy6rUoK3gV/3D3Q7PwyJpcSoUK33Wa7XbW1krOtnuzx02//+vQ4Dn3fD9bH9BcDvUR72pHQCwopBe+G4xiJ5N32/pdf75uSUwwp7P7kyQ7jsg90IRFksl6tt9vNqq0km30OP+7//L///deDc9ZaF2L8xsmT/cCKrRgpKcUYnTWJcrXe3n/85WMLU+juk8zjcbZ13poIEapZbe+2m1WjBZvtK9PvPv32P789pBhjit/0/DAHg9EIBrNpnBMIWa+3d/cff+mgQCmQZD59VnyhKXkhESGrZrXebFZtpQRFAIB86g+Pn/784/fHUgr8zY1WcrA5GE5KTqkUgpQwVXfb7Xa72XQT1xSPjRZLbeLFRBABEVXVdKvNZt01leIUcsrZHB4fHh8fd4d/DFclgJw8JSWnAkg55bru1tvNumsbPn8kKThdbNsvJYKEEEJp3a7Wm+123dVacMzeWdfvHn7/4+FwMv/4/pJjSZSQUjIgJVTW3Wq9+XC3brQ4c01x9mHekgghjHIuutXm7u7urmtrJShE0x/73cPnT78/9PY7HyADlIykQEGKTNbr7fZuc3e/quUkgxztYKz/1kFxVSJImRBKrzfb7d3dtqm0ZDT5cf/p4c9Pn3cPD6fwvRVKLhkJACJhQrfbjx8+rLerlWYAADl4Nx76wfr05kS40HW93mzu7u62lRCCYfbD/o/ffvvj4Xjqx+974AUKAiIg5bLuth9//bhe60pRAIje2bHfHU7G//UOujIRwqSuu9Vqs16vV4pRSiD5cf/pt//+/dF4575/H0+eLCIhTOh2fffxl3UrOKcA0VsznA77w8n4pTmHxTpCGVdV07Zt17WNRESE5E2/+/Nfv+18Lvm7X2TBAgVImfdWs9ps1w1BgpBj8NYMfT8aF76/0OuIAGFcKF3Vda21JgAAOXpnTsf9/vhjKxQAyACYSylIhaqaRk7/o+SUgnfOh7SUxwVbi3Ihp3DiZEWUFKN31ph/Pne/RMmAKcaUC1LGzwdvgZJzSjnl/OYeIhLKhZBSCEYnEyunOGPJOiUDBu9DTBnwi8uvlFLK8njQBUQYF0IIRmerLoUY5pDPEpQcwXsfYkopvzQQES9KNS+0MREmIpwxMn1pKXofQsqAC5cqOXo/U/n6IRcwWfh0QKSMc84ZJVgKQEnBOedjBkK//+4vUFKMIcQQ4xORMkcaL4hsLSZCCOOCC04JlgyQgjPGOp/yBV9jyTnnnNILIjmllNIFaazlxy+lnAvOOSUEIAVvx2EYrVuc/kcAMhcTnFFyCsG56QhYiMXKjoRSxjlnjCKUFMzpeDj0gw3Lno2ISPhcTnDmklPw1hhj/eL78ALHilA2gRLM0Q79frfb9+MP2CYvgEgIpUpJwRl9EkpJ3gynfhhsWFwVsZBIAURCGZ2qTCAHezo8PjzsjqNb9miklAmttXrpROXozND3/WDcm5vxMG2tSSKQgzntdw8Pu+Ow0O4mlAtV15VWnD0RKcGbU388XmAzXnD8Eso4Y5xRQrBEOxx3j4/73iwLQyFhXNVNU1dKPBEpObrx1B/7wbjF2r70QkRCGedCcM4IQo5uPB33h+Ng/KK9gJRJXbdt+5II5OjseDoN4wU6slgilHGplJxShSUGNw7DMBq/7PhFylXVdl1b6y8kEpwZx9H4sNRBXCwRSrlUVaUlp2Q2M6y1zi89fanQ7WqzWXe1ekEkR++stX65y75U2QnhUtd1UylOEKDkFMNsxC66i5HJerW9227XjX4qjphcq9kfeWMiyLiq6rZrFKcIWHKawooLeQAy1azuPmzvNu2LWFzJKQbv/ZzkWoSlEqFc6qZta8kpno2lvDwMhUy1m7uP203X6Kcob5mJhBgXq8hFROqmVXxOtOWccy6LbTzCdbPe3m+n1PwskZxSDCGEENPyiqGlW4swoXRVSYIEAUopOeeynAoVqu42m02nBSNniUzFmyHExTsVLiBCGRdSPnnZczXv0p3Fha6btusaSZ/Ozeicc85fJpDFRJBQxjg//73MWrLgG0RAQoSUSleVloJAKZBLyTkYY6xzk6qXNw9iI+Kz3V3mzbUoLz4FYpRSSklOABBKzjFFezoNo7E+pAvS7BeY8ecScQCYlGTaWj/+YKRMKCmlEPOJAZCj984cj/1ptC4uVxBYTqTAV6GaMollAQ9ChVJ6dkWmNXJwxpz2h+NpdBeYJwCXSORbnxrxh9P7SLlQdaWVFGceWFJw4+l4OBwHc4G9CACLba1ZKZ4ehVNh3Bfb7R+BfLqImkoJRs/0U7Rjf9gfjqephuACLN5ak3I/mUeEUsYYi+nH6nkoF0JVzWrV1lrw89FbcnDmdDweT6P1cWGlwIzFW6u81OzZPeGMku+UiyEQRCRcKFXV3Wq76Wr1nIHO0Y+nSdfDZTwW++zlSyUh0/UoQoB/vsPKVK2tVFU33Wq9vt92+iURO/bHw/E0Lg8rzbhAIvB8bCFlQiqtrCPfK0NGyoUQVd226/V6vVqtu+o5lV5mZT+Ny531GYslMl3l509HmNRaa+vc95SdMKG1btr1ZnO3WTd102r29J4c3dAfD/3JuIvOXrhE2XOKMc4WBFIuVVVb5+x3Ir9T6rHpVtu7D/fbdSWkUgzOhkgO1pyOfT/Yyy4RuEAiKXrvLJ9yTIQKVdWtc845/k/5XCpVVbdNt17ff/j44W6lKKXnawSgpODNcOpPxl7c5bOUSI7ejqeaEg4ABSmXVWP97ER8+z2IlHGp66ZrV+vN9v7+ftsJBATMs0Ryjs6acTTGX+BSXUYkeXPadzynilKChAldd1P9DGGhlDllhucsFAJQpIwJWdVN161W682qa2v95aI5xuCstdaHi+ysS4hE2z82PFrXKSU4k7rxafJRdO3mlAAiIQTJVNWPlHIuhNJ1006Fg406ezPTHVomz9DPMYzLeCwmEsxBsWhOxq0KAyarlIlQuqqbrjfBBx9SAUIZowQREJBwJqSUWtf11LHUVeIruyinFOOU8blYIMslMu4xmVPvYmFagsxAuK7rpu0O/eiMNT5MEpraLpBQLpTSSquqqitdKaUlOevGlBsqT9nUlC5vU1ouEYh26IcITDc1oEIqmqZpu+7Yj8MwDsYnZEJKzpEAQUKl1JXWWmmllZScMQapEMCnFE9JMUw50VfwWC4RE+w4DA5FvVoFDkRSGauqbtrjaTj1fT+6SJhUWnBCAAlhUlVVrfTUqMQoIpSIiLTMQYeSog8xxtlTf6+tlbK3xrgsm81xYzkAEbxIIZXS9VApKbSNhEuthSAEEAmTqq4qpbngjFJCJqMTCQAWhIIlpUnPY0rlFd1WS2/2DJBCKGK/3x8OijBCCKJESikTSnAuhomIkpwgICITSmstJWOk5IJYAMpz3rSUHIN3c5b6NV1jF9U0BjP0h91DzbLgXHACfPrqhVTV6CLhQknBCBYAJFxIKShmX3IpU2MPpQTnvpecgrPWOu8vCS++lggEOxwfWwlu6tMjyJEwoaSuR+MTMi4FJ4gZSkFCOYMccgw+xkKZUkpRghOVnIK31hrrwgWB69cTScH2j5pGU7dNSEVQpMhEkpW1PmSklDOGU9CrACCkmL0bR+cLU21XmJzy0phzDNaa0Rjnv1km/NZEILnTToAbV8bFXDJnhFJWRAghpIyEUEKglJRTzCnlmEKwp/442sLbbeEVUESCMJdIjaOx36zbfgci2Q2CJmdGF3LJWUpGCaLgeTJRpm87pxQx5hKC83Y47Pa9zWpdZJOQEEDA2QYdxtG4fxeRYBim4EPKUHKqouCCAiClpQAAlgIJIE/K7Kw1pt8/PB5N0UmtfD7fhiVHb804jMaF1+2sC4mU6CnBklMGhBy900pIznCiAAAll5RiDN57Z601ZjjtdrujLUEZl8pTiVaO3o7jONoLCmSvQQRy8gRLzmWKrdWVUopznAN1BUrOMcbgvfPOWWvNOOx3h5ND4kLK5ck6mbbWaRgvDWe9lkhJ0WPJOSVvTk1T1UorIc5EoJScYwjeeet9cM46O/aH3gQmYyovLsQUnBlPp8G4i33cVxLJKUDOKfix31dVVWmtBSeI8IKId9Y5H6IPPjhnhtGXkqYGuKdlojPDlFn/9xCBkqDkFL0dpFRKPxGZWwhLmYZVWOenWSgxOhcSoV9G889ETqN77UiOi4mUVHIMljHGhNBaVUoyglDKWUmC99ZYG0rOJZVUUsrIC06R4vMyKfh5a71S1y9v38uYEQEJImFMKa2V4IhQ5s9TUvTOGuvClHgALEAoBXyewQNPyj6M9sJkwuuJfJFSolIZpQR7SeRcxPD8KsKmvvaXgfucvDXGGLu4Fv5rXGVUQhpTjIFTPG8tgJKT986+jEjnxADxi51VylR98vr78FpzUTyUNB1aZyIlRf9V6dOUTMGXhb05BWeNMZcUbXyJKxEpESHNkwWmf8k5fZXpmFyRFyWM0ynurTH28sDcGdeaVFMSZAR81p1Svv6OKWOczXGi57dF76x1If2HSAQgn4nMKF83pTPOOZ8L1p4wXTfWx/JKHtciggXSX6a0ffHRKJtq6s/DLabXTHVSwefLyq9f4Fo68t2PgYRxoZR6TkoDTMGHGMIVJoosLQW8GEiYUEprJflz+QnOmaMrrP9uRIAyoaqqqqR4lsh5zt4Vln9HiXCp66apXlRjAk4Z+mtMeHlHiXBVNW1Ta8metxYSMochXot3I0KoUPXXRAC+Nr4uX/8Ka/wQkAldNe0Xhb6TQYNwDSbvRoQyoeumaeqn/ncASBd0F/8Nrj1w8m8w1ULWTdvUswMGpZRyad3fN/A+RKbEVd10XddowSkUyCXn5JwPMV7lHnkniRDGpa7btmsbPbvEOUVvrXPhdemEM95LIlxIXTdd19WSMwIl5xS9HY29qOz6G3gXIoiUCamrpmmailFKcYqlmtFYe0ln2Dfw9kSwTP07UlV101SaIJLJgXTjONpXR69nvINEEMhzgayWAHOmyjszGvt6b33C+xChjHEuhJRyLn0uOQVvxnF8dV7kjHfYWoiUMcEF55zNdyFCjsHZcTSvD/rOeAeJkKkti3NG6bmqa4rMjcNofbjOaOy3N1EQCeNTnzIlL0OMZkpVvTp+MuEdiBDKGBecU/oiEpSDs8MwjMb9NBIBJJRPzb0vog4p2HGYotc/kUSmImf6olU6p+BmIj+RRJBSyhil9EUYPnoz9MfjFVJVM95BIoBIKPkyL1KSN6fD/tAPP9HxO6dEXvKAHN1w3D/uh1cUyH6J9zAa5y6gL2YJRDf2+93e2p+HCOK8tRCfQ8M52OG43x1CuJKp9T5bayptoi9VZFL2PqXrxBnfRyKUsql+7olJisHZcTgNF84O+QbegQihXExT7+kcIC0xBu/cj8yw+mG8AxHK557DKXpdSkkhTFXoV3zMO9wjlMuqrutqijpMCjJVXV/zx3a8ORGcR2g19Tz5u+Q0t6xf9efqvL1ECBP6RdC3lByDcz6m8pMRQSp0PQV9J4mkOEmkLJ3/9I94FyKqmhoPKcFSco7e/qRbS1VNe56AUnKK3nt/pUjpE97++CVM1d16vWorJTkCwpTIDa9osfgW3oGIUM16e99UlWQAQLDkFEJ8dYXAV3gHIlw3q82dVnL+h3nS2c9HhMm6Xa3lixa3MI2t+8mIIOVCVer81/JU6nhdIu/is78sozHjOIzD9WK+Z7y9REqO3hmHU12AGfrD4XDsB7twbNL38PZEsh8ODy3gNLjQmNPxcNwfDidzJR93xtsTiePhk84HnEZrWDsO/anvD8fx4v7ib+LtiYThUaZ+Nf/UmuCcGc04Dqdh4dS67+DNiZQwPOThUzXNhIcYg3feeWvszyaROGS7UxzmQb8ppRRjCjFcOG7jb3D1H376F8zdYQDnsvmSp0ke+TXdejfccMMNN9xwww0/A/4fHMNh6BLlqDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x1C652F9AFA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([[2.2411e-05, 4.9409e-07, 3.8254e-05, 1.8362e-04, 2.9749e-04, 7.0736e-05,\n",
      "         1.6132e-06, 3.4059e-03, 1.2733e-04, 9.9585e-01]],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkest\\Documents\\OMSCS\\Deep_Learning\\project\\omscs-dl-final-project\\team36\\training.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return nn.functional.softmax(out)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x1C652F93130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([[1.2416e-04, 1.2717e-05, 3.2222e-04, 6.8261e-04, 2.4576e-03, 4.9085e-04,\n",
      "         1.4254e-05, 2.3854e-02, 2.4717e-04, 9.7179e-01]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "True label tensor(9)\n"
     ]
    }
   ],
   "source": [
    "model = oracle\n",
    "index = 16\n",
    "# some clear images: 1=ship, 16=dog\n",
    "disp_width, disp_height = 200, 200\n",
    "\n",
    "input, _ = test_set[index]\n",
    "img = transforms.functional.to_pil_image(input)\n",
    "display(img.resize((disp_width, disp_height)))\n",
    "print(predict(model, input, soft=False))\n",
    "print(predict(model, input, soft=True))\n",
    "\n",
    "input, _ = attack_test_set[index]\n",
    "attack_img = transforms.functional.to_pil_image(input)\n",
    "display(attack_img.resize((disp_width, disp_height)))\n",
    "print(predict(model, input, soft=False))\n",
    "print(predict(model, input, soft=True))\n",
    "\n",
    "print('True label', test_set.targets[index])\n",
    "\n",
    "# input, _ = attack_test_set[index]\n",
    "# display(transforms.functional.to_pil_image(input))\n",
    "# print(predict(defense_model, input))\n",
    "\n",
    "# input, _ = attack_test_set[index]\n",
    "# display(transforms.functional.to_pil_image(input))\n",
    "# print(predict(fgsm_reg_defense_model, input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ca853-1ebe-4d5d-8845-d6f3c50a693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = iter(test_loader).next()[0]\n",
    "J = jacobian(sub, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba46b6-245b-4f17-a474-7c9608468306",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = iter(test_loader).next()[0]\n",
    "J = jacobian(sub, batch[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99317b2-7324-43b8-8fc0-84d098e60a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ef822-7688-4dd8-b028-a795bf53ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.squeeze(0).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990fdec-4c92-4470-ace0-0e2b1f96bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jlabel = J[:,0,:,:,:,:]\n",
    "Jlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a3b46-1c62-420d-b6ff-87b1bf40be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "J[:,0,:,:,:,:].squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df5599-937f-4245-ade6-9806ded789bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jsum = torch.sum(Jlabel, axis=0)\n",
    "Jsum = torch.sum(Jsum, axis=0)\n",
    "Jsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a756a-9e1a-4740-833f-fa7e9d706fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "J[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40576d-afac-4140-a4c6-383e8d780096",
   "metadata": {},
   "outputs": [],
   "source": [
    "J[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc014d3c-7a0d-4823-a5ac-a1e07638334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(test_loader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c83bae-d29e-4361-947f-13b75605e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(test_loader).next()[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56ace2-0232-4f44-ad0d-8eef43d39394",
   "metadata": {},
   "outputs": [],
   "source": [
    "(iter(test_loader).next()[0] + J).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b473f-c6d1-417f-af2a-f676c8eaa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(test_loader).next()[0]\n",
    "sub(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac1c26-5dd5-45b5-abd3-c41f727c2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_batch = batch + J\n",
    "sub(modified_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e15085-0a01-4a37-b6f7-a364748b8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch + J).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec13bf9-82e8-46cd-b4d2-c26ee1fd77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(J + batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb6368-c598-47b3-9045-21d23d95fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze(J + batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586bdd4-de0a-4d98-9d32-3b70c8528661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dub(x):\n",
    "    return x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6f1ac-6ae0-46a2-9668-30cf5d8cc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = jacobian(dub, torch.tensor([[3., 4., 2.], [1,2,3], [5,3,4], [5,2,3]]))\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8133d1-d872-48d2-ad2b-3ccf33e884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = jacobian(dub, torch.tensor([[3., 4., 2.]]))\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b182f-f0d4-404e-937a-1769a91ad3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.squeeze(0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-final-project-cpu",
   "language": "python",
   "name": "cs7643-final-project-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
