{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_stat_def_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7435d5696d3485f90b9a5286197aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e136c1826934a44949eb14e8c1d4d42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff5519e0aef441e5ae0ab20553ca35df",
              "IPY_MODEL_9bcb9e68df454fb18a01fc46a3760ad5"
            ]
          }
        },
        "1e136c1826934a44949eb14e8c1d4d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff5519e0aef441e5ae0ab20553ca35df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d954d9fe8a0e4f0fa830b91b91043c90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_143053713bee459a8501bc00a5fa65de"
          }
        },
        "9bcb9e68df454fb18a01fc46a3760ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f543c21b3604d529f2f7ce4bdf34726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [03:16&lt;00:00, 866882.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37a6597b0fdb4923ab1eefa61fc12c86"
          }
        },
        "d954d9fe8a0e4f0fa830b91b91043c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "143053713bee459a8501bc00a5fa65de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f543c21b3604d529f2f7ce4bdf34726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37a6597b0fdb4923ab1eefa61fc12c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gog-ZK9aXq1"
      },
      "source": [
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "c7435d5696d3485f90b9a5286197aed8",
            "1e136c1826934a44949eb14e8c1d4d42",
            "ff5519e0aef441e5ae0ab20553ca35df",
            "9bcb9e68df454fb18a01fc46a3760ad5",
            "d954d9fe8a0e4f0fa830b91b91043c90",
            "143053713bee459a8501bc00a5fa65de",
            "8f543c21b3604d529f2f7ce4bdf34726",
            "37a6597b0fdb4923ab1eefa61fc12c86"
          ]
        },
        "id": "SuyYEfQZawkL",
        "outputId": "c33bcb34-dc03-45df-d4fc-e4b5c9c1f674"
      },
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "DIR = \"/content/drive/MyDrive/OMSCS/DL/FinalProject\"\n",
        "DATA_DIR = f'{DIR}/data'\n",
        "NAME = 'cifar10'\n",
        "\n",
        "sys.path.append(os.path.abspath(DIR))\n",
        "\n",
        "training_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, \n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "training_indices, validation_indices, _, _ = train_test_split(\n",
        "    range(len(training_set)),\n",
        "    training_set.targets,\n",
        "    stratify=training_set.targets,\n",
        "    test_size=0.1,\n",
        ")\n",
        "training_split = torch.utils.data.Subset(training_set, training_indices)\n",
        "validation_split = torch.utils.data.Subset(training_set, validation_indices)\n",
        "\n",
        "print(f\"{len(training_split)} in training set\")\n",
        "print(f\"{len(validation_split)} in validation set\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/OMSCS/DL/FinalProject/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7435d5696d3485f90b9a5286197aed8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /content/drive/MyDrive/OMSCS/DL/FinalProject/data/cifar-10-python.tar.gz to /content/drive/MyDrive/OMSCS/DL/FinalProject/data\n",
            "45000 in training set\n",
            "5000 in validation set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4TlgaRria1UE",
        "outputId": "08fc36d4-1af8-4594-b6b5-3c0ee3949027"
      },
      "source": [
        "import team36\n",
        "from team36.defenses.stat_def import VGG\n",
        "from team36.training import train, validate\n",
        "\n",
        "learning_rate = 5e-4\n",
        "momentum = 5e-1\n",
        "weight_decay = 1e-1\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_split, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(validation_split, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "model = VGG(image_size=32, in_channels=3)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
        "                            momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "best = 0.0\n",
        "best_cm = None\n",
        "best_model = None\n",
        "train_accuracy_history = []\n",
        "train_loss_history = []\n",
        "validation_accuracy_history = []\n",
        "validation_loss_history = []\n",
        "for epoch in range(epochs):\n",
        "    train_acc, train_loss = train(epoch, training_loader, model, optimizer, criterion)\n",
        "    train_accuracy_history.append(train_acc)\n",
        "    train_loss_history.append(train_loss)\n",
        "    \n",
        "    acc, cm, loss = validate(epoch, test_loader, model, criterion)\n",
        "    validation_accuracy_history.append(acc)\n",
        "    validation_loss_history.append(loss)\n",
        "    \n",
        "    print(\"Epoch {0} | Training accuracy: {1}% | Validation accuracy: {2}%\".format(epoch, train_acc, acc))\n",
        "    \n",
        "    if acc > best:\n",
        "        best = acc\n",
        "        best_cm = cm\n",
        "        best_model = copy.deepcopy(model)\n",
        "        \n",
        "training_curve, = plt.plot(train_accuracy_history, label='training')\n",
        "validation_curve, = plt.plot(validation_accuracy_history, label='validation')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend(handles=[training_curve, validation_curve])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "training_curve, = plt.plot(train_loss_history, label='training')\n",
        "validation_curve, = plt.plot(validation_loss_history, label='validation')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend(handles=[training_curve, validation_curve])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "print('Best Validation Acccuracy: {:.4f}'.format(best))\n",
        "\n",
        "torch.save(best_model.state_dict(), f\"{DIR}/checkpoints/{NAME}-vgg.pth\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/1407]\tLoss 2.3983 (2.3983)\tPrec @1 0.0938 (0.0938)\t\n",
            "Epoch: [0][10/1407]\tLoss 2.2464 (2.3108)\tPrec @1 0.1562 (0.1733)\t\n",
            "Epoch: [0][20/1407]\tLoss 1.9102 (2.2061)\tPrec @1 0.3125 (0.2128)\t\n",
            "Epoch: [0][30/1407]\tLoss 1.8294 (2.1639)\tPrec @1 0.3750 (0.2198)\t\n",
            "Epoch: [0][40/1407]\tLoss 2.0055 (2.1286)\tPrec @1 0.3125 (0.2393)\t\n",
            "Epoch: [0][50/1407]\tLoss 1.8317 (2.0988)\tPrec @1 0.3125 (0.2537)\t\n",
            "Epoch: [0][60/1407]\tLoss 1.8454 (2.0683)\tPrec @1 0.4062 (0.2643)\t\n",
            "Epoch: [0][70/1407]\tLoss 1.7851 (2.0293)\tPrec @1 0.4688 (0.2821)\t\n",
            "Epoch: [0][80/1407]\tLoss 1.8926 (2.0009)\tPrec @1 0.3438 (0.2940)\t\n",
            "Epoch: [0][90/1407]\tLoss 1.5856 (1.9777)\tPrec @1 0.4688 (0.3001)\t\n",
            "Epoch: [0][100/1407]\tLoss 1.7829 (1.9635)\tPrec @1 0.3750 (0.3041)\t\n",
            "Epoch: [0][110/1407]\tLoss 1.7813 (1.9462)\tPrec @1 0.3438 (0.3086)\t\n",
            "Epoch: [0][120/1407]\tLoss 1.6624 (1.9256)\tPrec @1 0.3750 (0.3156)\t\n",
            "Epoch: [0][130/1407]\tLoss 1.4105 (1.9024)\tPrec @1 0.5000 (0.3251)\t\n",
            "Epoch: [0][140/1407]\tLoss 1.5762 (1.8946)\tPrec @1 0.4688 (0.3278)\t\n",
            "Epoch: [0][150/1407]\tLoss 1.6162 (1.8841)\tPrec @1 0.3125 (0.3286)\t\n",
            "Epoch: [0][160/1407]\tLoss 1.4370 (1.8701)\tPrec @1 0.5312 (0.3340)\t\n",
            "Epoch: [0][170/1407]\tLoss 1.6186 (1.8630)\tPrec @1 0.3125 (0.3361)\t\n",
            "Epoch: [0][180/1407]\tLoss 1.6465 (1.8520)\tPrec @1 0.4688 (0.3412)\t\n",
            "Epoch: [0][190/1407]\tLoss 1.4962 (1.8359)\tPrec @1 0.4375 (0.3452)\t\n",
            "Epoch: [0][200/1407]\tLoss 1.7685 (1.8273)\tPrec @1 0.3438 (0.3479)\t\n",
            "Epoch: [0][210/1407]\tLoss 2.2449 (1.8197)\tPrec @1 0.2812 (0.3503)\t\n",
            "Epoch: [0][220/1407]\tLoss 1.8104 (1.8113)\tPrec @1 0.3125 (0.3531)\t\n",
            "Epoch: [0][230/1407]\tLoss 1.4797 (1.8054)\tPrec @1 0.5625 (0.3559)\t\n",
            "Epoch: [0][240/1407]\tLoss 1.4468 (1.7962)\tPrec @1 0.4688 (0.3597)\t\n",
            "Epoch: [0][250/1407]\tLoss 1.4635 (1.7883)\tPrec @1 0.4375 (0.3618)\t\n",
            "Epoch: [0][260/1407]\tLoss 1.5807 (1.7782)\tPrec @1 0.4688 (0.3660)\t\n",
            "Epoch: [0][270/1407]\tLoss 1.7179 (1.7697)\tPrec @1 0.4062 (0.3693)\t\n",
            "Epoch: [0][280/1407]\tLoss 1.1719 (1.7592)\tPrec @1 0.5000 (0.3726)\t\n",
            "Epoch: [0][290/1407]\tLoss 1.4975 (1.7510)\tPrec @1 0.4688 (0.3752)\t\n",
            "Epoch: [0][300/1407]\tLoss 1.5967 (1.7451)\tPrec @1 0.4062 (0.3768)\t\n",
            "Epoch: [0][310/1407]\tLoss 1.4095 (1.7387)\tPrec @1 0.4375 (0.3777)\t\n",
            "Epoch: [0][320/1407]\tLoss 1.4993 (1.7323)\tPrec @1 0.5938 (0.3808)\t\n",
            "Epoch: [0][330/1407]\tLoss 1.1615 (1.7237)\tPrec @1 0.6875 (0.3833)\t\n",
            "Epoch: [0][340/1407]\tLoss 1.2567 (1.7184)\tPrec @1 0.5625 (0.3848)\t\n",
            "Epoch: [0][350/1407]\tLoss 1.4757 (1.7106)\tPrec @1 0.4062 (0.3876)\t\n",
            "Epoch: [0][360/1407]\tLoss 1.4488 (1.7049)\tPrec @1 0.5000 (0.3898)\t\n",
            "Epoch: [0][370/1407]\tLoss 1.5449 (1.7022)\tPrec @1 0.5625 (0.3913)\t\n",
            "Epoch: [0][380/1407]\tLoss 1.4932 (1.6968)\tPrec @1 0.4688 (0.3927)\t\n",
            "Epoch: [0][390/1407]\tLoss 1.5060 (1.6916)\tPrec @1 0.4062 (0.3948)\t\n",
            "Epoch: [0][400/1407]\tLoss 1.6049 (1.6864)\tPrec @1 0.3438 (0.3967)\t\n",
            "Epoch: [0][410/1407]\tLoss 1.1224 (1.6793)\tPrec @1 0.6562 (0.3990)\t\n",
            "Epoch: [0][420/1407]\tLoss 1.3822 (1.6768)\tPrec @1 0.4375 (0.3999)\t\n",
            "Epoch: [0][430/1407]\tLoss 1.3145 (1.6715)\tPrec @1 0.5000 (0.4010)\t\n",
            "Epoch: [0][440/1407]\tLoss 1.6308 (1.6671)\tPrec @1 0.3750 (0.4024)\t\n",
            "Epoch: [0][450/1407]\tLoss 1.8411 (1.6633)\tPrec @1 0.3438 (0.4036)\t\n",
            "Epoch: [0][460/1407]\tLoss 1.2922 (1.6585)\tPrec @1 0.5312 (0.4051)\t\n",
            "Epoch: [0][470/1407]\tLoss 1.3548 (1.6553)\tPrec @1 0.5312 (0.4066)\t\n",
            "Epoch: [0][480/1407]\tLoss 1.4665 (1.6508)\tPrec @1 0.5312 (0.4083)\t\n",
            "Epoch: [0][490/1407]\tLoss 1.3312 (1.6462)\tPrec @1 0.5312 (0.4096)\t\n",
            "Epoch: [0][500/1407]\tLoss 1.6619 (1.6429)\tPrec @1 0.5000 (0.4114)\t\n",
            "Epoch: [0][510/1407]\tLoss 1.3183 (1.6398)\tPrec @1 0.5625 (0.4119)\t\n",
            "Epoch: [0][520/1407]\tLoss 1.1283 (1.6362)\tPrec @1 0.5312 (0.4130)\t\n",
            "Epoch: [0][530/1407]\tLoss 1.4943 (1.6312)\tPrec @1 0.5312 (0.4151)\t\n",
            "Epoch: [0][540/1407]\tLoss 1.4683 (1.6279)\tPrec @1 0.6562 (0.4163)\t\n",
            "Epoch: [0][550/1407]\tLoss 1.5798 (1.6244)\tPrec @1 0.5000 (0.4179)\t\n",
            "Epoch: [0][560/1407]\tLoss 1.5539 (1.6192)\tPrec @1 0.4375 (0.4197)\t\n",
            "Epoch: [0][570/1407]\tLoss 1.3527 (1.6138)\tPrec @1 0.6250 (0.4219)\t\n",
            "Epoch: [0][580/1407]\tLoss 1.3659 (1.6084)\tPrec @1 0.4375 (0.4238)\t\n",
            "Epoch: [0][590/1407]\tLoss 1.5528 (1.6058)\tPrec @1 0.4062 (0.4247)\t\n",
            "Epoch: [0][600/1407]\tLoss 1.2870 (1.6016)\tPrec @1 0.5312 (0.4265)\t\n",
            "Epoch: [0][610/1407]\tLoss 1.4621 (1.5988)\tPrec @1 0.4375 (0.4278)\t\n",
            "Epoch: [0][620/1407]\tLoss 1.3795 (1.5948)\tPrec @1 0.5625 (0.4291)\t\n",
            "Epoch: [0][630/1407]\tLoss 1.3500 (1.5932)\tPrec @1 0.5625 (0.4300)\t\n",
            "Epoch: [0][640/1407]\tLoss 1.4500 (1.5903)\tPrec @1 0.5625 (0.4311)\t\n",
            "Epoch: [0][650/1407]\tLoss 1.5228 (1.5879)\tPrec @1 0.5312 (0.4326)\t\n",
            "Epoch: [0][660/1407]\tLoss 1.4117 (1.5833)\tPrec @1 0.5625 (0.4347)\t\n",
            "Epoch: [0][670/1407]\tLoss 1.4280 (1.5791)\tPrec @1 0.4375 (0.4364)\t\n",
            "Epoch: [0][680/1407]\tLoss 1.2630 (1.5771)\tPrec @1 0.5312 (0.4374)\t\n",
            "Epoch: [0][690/1407]\tLoss 1.5679 (1.5745)\tPrec @1 0.3438 (0.4388)\t\n",
            "Epoch: [0][700/1407]\tLoss 1.6229 (1.5720)\tPrec @1 0.3438 (0.4389)\t\n",
            "Epoch: [0][710/1407]\tLoss 1.7571 (1.5704)\tPrec @1 0.3438 (0.4399)\t\n",
            "Epoch: [0][720/1407]\tLoss 1.4447 (1.5664)\tPrec @1 0.5625 (0.4417)\t\n",
            "Epoch: [0][730/1407]\tLoss 1.6481 (1.5639)\tPrec @1 0.4062 (0.4424)\t\n",
            "Epoch: [0][740/1407]\tLoss 1.4581 (1.5614)\tPrec @1 0.5000 (0.4437)\t\n",
            "Epoch: [0][750/1407]\tLoss 1.3274 (1.5591)\tPrec @1 0.5625 (0.4446)\t\n",
            "Epoch: [0][760/1407]\tLoss 1.0052 (1.5558)\tPrec @1 0.6250 (0.4453)\t\n",
            "Epoch: [0][770/1407]\tLoss 1.2217 (1.5537)\tPrec @1 0.5938 (0.4463)\t\n",
            "Epoch: [0][780/1407]\tLoss 1.1471 (1.5509)\tPrec @1 0.5938 (0.4471)\t\n",
            "Epoch: [0][790/1407]\tLoss 1.3915 (1.5481)\tPrec @1 0.5625 (0.4485)\t\n",
            "Epoch: [0][800/1407]\tLoss 1.2395 (1.5454)\tPrec @1 0.5625 (0.4493)\t\n",
            "Epoch: [0][810/1407]\tLoss 1.2304 (1.5420)\tPrec @1 0.5000 (0.4505)\t\n",
            "Epoch: [0][820/1407]\tLoss 1.2945 (1.5395)\tPrec @1 0.5000 (0.4514)\t\n",
            "Epoch: [0][830/1407]\tLoss 1.2011 (1.5358)\tPrec @1 0.5938 (0.4526)\t\n",
            "Epoch: [0][840/1407]\tLoss 1.1138 (1.5339)\tPrec @1 0.6250 (0.4534)\t\n",
            "Epoch: [0][850/1407]\tLoss 1.3279 (1.5309)\tPrec @1 0.4688 (0.4544)\t\n",
            "Epoch: [0][860/1407]\tLoss 1.3309 (1.5294)\tPrec @1 0.5938 (0.4551)\t\n",
            "Epoch: [0][870/1407]\tLoss 1.3403 (1.5279)\tPrec @1 0.5625 (0.4557)\t\n",
            "Epoch: [0][880/1407]\tLoss 1.1894 (1.5255)\tPrec @1 0.5625 (0.4565)\t\n",
            "Epoch: [0][890/1407]\tLoss 1.3601 (1.5233)\tPrec @1 0.4688 (0.4572)\t\n",
            "Epoch: [0][900/1407]\tLoss 0.9428 (1.5202)\tPrec @1 0.7188 (0.4584)\t\n",
            "Epoch: [0][910/1407]\tLoss 1.4459 (1.5175)\tPrec @1 0.4688 (0.4592)\t\n",
            "Epoch: [0][920/1407]\tLoss 1.3525 (1.5143)\tPrec @1 0.4688 (0.4602)\t\n",
            "Epoch: [0][930/1407]\tLoss 1.3556 (1.5121)\tPrec @1 0.5938 (0.4610)\t\n",
            "Epoch: [0][940/1407]\tLoss 1.1017 (1.5106)\tPrec @1 0.6562 (0.4618)\t\n",
            "Epoch: [0][950/1407]\tLoss 1.2909 (1.5085)\tPrec @1 0.5000 (0.4625)\t\n",
            "Epoch: [0][960/1407]\tLoss 1.1988 (1.5070)\tPrec @1 0.5312 (0.4628)\t\n",
            "Epoch: [0][970/1407]\tLoss 1.2698 (1.5049)\tPrec @1 0.5000 (0.4635)\t\n",
            "Epoch: [0][980/1407]\tLoss 1.2679 (1.5025)\tPrec @1 0.5312 (0.4645)\t\n",
            "Epoch: [0][990/1407]\tLoss 1.2217 (1.5006)\tPrec @1 0.6250 (0.4651)\t\n",
            "Epoch: [0][1000/1407]\tLoss 1.4529 (1.4990)\tPrec @1 0.4688 (0.4657)\t\n",
            "Epoch: [0][1010/1407]\tLoss 1.1686 (1.4970)\tPrec @1 0.5938 (0.4665)\t\n",
            "Epoch: [0][1020/1407]\tLoss 1.0821 (1.4948)\tPrec @1 0.5312 (0.4670)\t\n",
            "Epoch: [0][1030/1407]\tLoss 1.3397 (1.4925)\tPrec @1 0.4375 (0.4679)\t\n",
            "Epoch: [0][1040/1407]\tLoss 1.2606 (1.4903)\tPrec @1 0.5625 (0.4686)\t\n",
            "Epoch: [0][1050/1407]\tLoss 1.1801 (1.4885)\tPrec @1 0.5625 (0.4691)\t\n",
            "Epoch: [0][1060/1407]\tLoss 1.2218 (1.4866)\tPrec @1 0.6250 (0.4699)\t\n",
            "Epoch: [0][1070/1407]\tLoss 1.3111 (1.4846)\tPrec @1 0.5625 (0.4706)\t\n",
            "Epoch: [0][1080/1407]\tLoss 1.2903 (1.4821)\tPrec @1 0.4688 (0.4715)\t\n",
            "Epoch: [0][1090/1407]\tLoss 1.3068 (1.4806)\tPrec @1 0.6250 (0.4721)\t\n",
            "Epoch: [0][1100/1407]\tLoss 1.6359 (1.4783)\tPrec @1 0.4688 (0.4730)\t\n",
            "Epoch: [0][1110/1407]\tLoss 0.9887 (1.4757)\tPrec @1 0.6250 (0.4740)\t\n",
            "Epoch: [0][1120/1407]\tLoss 1.3715 (1.4745)\tPrec @1 0.4688 (0.4742)\t\n",
            "Epoch: [0][1130/1407]\tLoss 1.2899 (1.4731)\tPrec @1 0.5938 (0.4750)\t\n",
            "Epoch: [0][1140/1407]\tLoss 0.9390 (1.4709)\tPrec @1 0.6250 (0.4757)\t\n",
            "Epoch: [0][1150/1407]\tLoss 1.3326 (1.4698)\tPrec @1 0.4375 (0.4763)\t\n",
            "Epoch: [0][1160/1407]\tLoss 1.2720 (1.4683)\tPrec @1 0.6250 (0.4769)\t\n",
            "Epoch: [0][1170/1407]\tLoss 1.0089 (1.4656)\tPrec @1 0.6250 (0.4782)\t\n",
            "Epoch: [0][1180/1407]\tLoss 1.3413 (1.4627)\tPrec @1 0.6250 (0.4793)\t\n",
            "Epoch: [0][1190/1407]\tLoss 1.2862 (1.4604)\tPrec @1 0.5938 (0.4803)\t\n",
            "Epoch: [0][1200/1407]\tLoss 1.5074 (1.4584)\tPrec @1 0.5312 (0.4811)\t\n",
            "Epoch: [0][1210/1407]\tLoss 1.1231 (1.4559)\tPrec @1 0.5625 (0.4821)\t\n",
            "Epoch: [0][1220/1407]\tLoss 1.2052 (1.4542)\tPrec @1 0.5938 (0.4826)\t\n",
            "Epoch: [0][1230/1407]\tLoss 1.0708 (1.4523)\tPrec @1 0.6562 (0.4835)\t\n",
            "Epoch: [0][1240/1407]\tLoss 1.1286 (1.4505)\tPrec @1 0.5625 (0.4844)\t\n",
            "Epoch: [0][1250/1407]\tLoss 1.2700 (1.4483)\tPrec @1 0.5312 (0.4855)\t\n",
            "Epoch: [0][1260/1407]\tLoss 1.2132 (1.4466)\tPrec @1 0.5625 (0.4859)\t\n",
            "Epoch: [0][1270/1407]\tLoss 1.1644 (1.4439)\tPrec @1 0.5938 (0.4870)\t\n",
            "Epoch: [0][1280/1407]\tLoss 1.1985 (1.4422)\tPrec @1 0.5625 (0.4876)\t\n",
            "Epoch: [0][1290/1407]\tLoss 1.4227 (1.4406)\tPrec @1 0.5312 (0.4880)\t\n",
            "Epoch: [0][1300/1407]\tLoss 1.0530 (1.4388)\tPrec @1 0.6562 (0.4886)\t\n",
            "Epoch: [0][1310/1407]\tLoss 1.0146 (1.4364)\tPrec @1 0.6562 (0.4895)\t\n",
            "Epoch: [0][1320/1407]\tLoss 1.2596 (1.4347)\tPrec @1 0.5312 (0.4903)\t\n",
            "Epoch: [0][1330/1407]\tLoss 1.3792 (1.4333)\tPrec @1 0.5000 (0.4907)\t\n",
            "Epoch: [0][1340/1407]\tLoss 1.0252 (1.4319)\tPrec @1 0.6875 (0.4915)\t\n",
            "Epoch: [0][1350/1407]\tLoss 1.2930 (1.4307)\tPrec @1 0.5312 (0.4917)\t\n",
            "Epoch: [0][1360/1407]\tLoss 1.1692 (1.4293)\tPrec @1 0.5312 (0.4923)\t\n",
            "Epoch: [0][1370/1407]\tLoss 1.1178 (1.4268)\tPrec @1 0.6250 (0.4934)\t\n",
            "Epoch: [0][1380/1407]\tLoss 1.5387 (1.4258)\tPrec @1 0.3750 (0.4939)\t\n",
            "Epoch: [0][1390/1407]\tLoss 1.5564 (1.4238)\tPrec @1 0.5000 (0.4947)\t\n",
            "Epoch: [0][1400/1407]\tLoss 0.9487 (1.4219)\tPrec @1 0.7188 (0.4954)\t\n",
            "Epoch 0 | Training accuracy: 0.49575555324554443% | Validation accuracy: 0.5275999903678894%\n",
            "Epoch: [1][0/1407]\tLoss 1.2045 (1.2045)\tPrec @1 0.5312 (0.5312)\t\n",
            "Epoch: [1][10/1407]\tLoss 1.2026 (1.0883)\tPrec @1 0.5625 (0.5909)\t\n",
            "Epoch: [1][20/1407]\tLoss 0.9893 (1.1052)\tPrec @1 0.6875 (0.6057)\t\n",
            "Epoch: [1][30/1407]\tLoss 1.0068 (1.1182)\tPrec @1 0.6875 (0.6129)\t\n",
            "Epoch: [1][40/1407]\tLoss 1.3945 (1.1372)\tPrec @1 0.5312 (0.6105)\t\n",
            "Epoch: [1][50/1407]\tLoss 0.9689 (1.1452)\tPrec @1 0.6562 (0.6066)\t\n",
            "Epoch: [1][60/1407]\tLoss 1.0776 (1.1364)\tPrec @1 0.6250 (0.6137)\t\n",
            "Epoch: [1][70/1407]\tLoss 1.0115 (1.1321)\tPrec @1 0.6875 (0.6105)\t\n",
            "Epoch: [1][80/1407]\tLoss 1.3585 (1.1361)\tPrec @1 0.5625 (0.6092)\t\n",
            "Epoch: [1][90/1407]\tLoss 1.1460 (1.1400)\tPrec @1 0.5938 (0.6058)\t\n",
            "Epoch: [1][100/1407]\tLoss 1.0086 (1.1443)\tPrec @1 0.5625 (0.6040)\t\n",
            "Epoch: [1][110/1407]\tLoss 1.0652 (1.1441)\tPrec @1 0.6250 (0.6059)\t\n",
            "Epoch: [1][120/1407]\tLoss 0.9335 (1.1433)\tPrec @1 0.6562 (0.6080)\t\n",
            "Epoch: [1][130/1407]\tLoss 0.8765 (1.1353)\tPrec @1 0.6250 (0.6104)\t\n",
            "Epoch: [1][140/1407]\tLoss 1.1921 (1.1434)\tPrec @1 0.5312 (0.6073)\t\n",
            "Epoch: [1][150/1407]\tLoss 1.1693 (1.1429)\tPrec @1 0.5938 (0.6062)\t\n",
            "Epoch: [1][160/1407]\tLoss 1.1075 (1.1429)\tPrec @1 0.6562 (0.6066)\t\n",
            "Epoch: [1][170/1407]\tLoss 1.1557 (1.1438)\tPrec @1 0.6250 (0.6047)\t\n",
            "Epoch: [1][180/1407]\tLoss 1.2900 (1.1421)\tPrec @1 0.5938 (0.6057)\t\n",
            "Epoch: [1][190/1407]\tLoss 1.1041 (1.1330)\tPrec @1 0.6250 (0.6083)\t\n",
            "Epoch: [1][200/1407]\tLoss 1.2994 (1.1338)\tPrec @1 0.6250 (0.6081)\t\n",
            "Epoch: [1][210/1407]\tLoss 1.6283 (1.1367)\tPrec @1 0.4375 (0.6074)\t\n",
            "Epoch: [1][220/1407]\tLoss 1.4042 (1.1405)\tPrec @1 0.5000 (0.6058)\t\n",
            "Epoch: [1][230/1407]\tLoss 0.9620 (1.1441)\tPrec @1 0.7188 (0.6044)\t\n",
            "Epoch: [1][240/1407]\tLoss 0.9001 (1.1397)\tPrec @1 0.6250 (0.6046)\t\n",
            "Epoch: [1][250/1407]\tLoss 1.0509 (1.1385)\tPrec @1 0.6875 (0.6041)\t\n",
            "Epoch: [1][260/1407]\tLoss 1.1226 (1.1347)\tPrec @1 0.5938 (0.6061)\t\n",
            "Epoch: [1][270/1407]\tLoss 1.2993 (1.1361)\tPrec @1 0.4688 (0.6053)\t\n",
            "Epoch: [1][280/1407]\tLoss 0.8006 (1.1322)\tPrec @1 0.6562 (0.6064)\t\n",
            "Epoch: [1][290/1407]\tLoss 1.1390 (1.1292)\tPrec @1 0.5625 (0.6086)\t\n",
            "Epoch: [1][300/1407]\tLoss 1.2731 (1.1301)\tPrec @1 0.6562 (0.6087)\t\n",
            "Epoch: [1][310/1407]\tLoss 0.9152 (1.1292)\tPrec @1 0.7812 (0.6087)\t\n",
            "Epoch: [1][320/1407]\tLoss 1.1285 (1.1282)\tPrec @1 0.7188 (0.6095)\t\n",
            "Epoch: [1][330/1407]\tLoss 0.8766 (1.1255)\tPrec @1 0.6875 (0.6094)\t\n",
            "Epoch: [1][340/1407]\tLoss 0.8712 (1.1264)\tPrec @1 0.5938 (0.6088)\t\n",
            "Epoch: [1][350/1407]\tLoss 1.1232 (1.1249)\tPrec @1 0.6250 (0.6098)\t\n",
            "Epoch: [1][360/1407]\tLoss 1.1259 (1.1260)\tPrec @1 0.5938 (0.6096)\t\n",
            "Epoch: [1][370/1407]\tLoss 1.1604 (1.1277)\tPrec @1 0.6875 (0.6095)\t\n",
            "Epoch: [1][380/1407]\tLoss 1.0838 (1.1278)\tPrec @1 0.5312 (0.6088)\t\n",
            "Epoch: [1][390/1407]\tLoss 1.1618 (1.1269)\tPrec @1 0.6875 (0.6096)\t\n",
            "Epoch: [1][400/1407]\tLoss 1.4112 (1.1273)\tPrec @1 0.4688 (0.6096)\t\n",
            "Epoch: [1][410/1407]\tLoss 0.9831 (1.1260)\tPrec @1 0.5938 (0.6105)\t\n",
            "Epoch: [1][420/1407]\tLoss 0.9767 (1.1266)\tPrec @1 0.6250 (0.6105)\t\n",
            "Epoch: [1][430/1407]\tLoss 0.8020 (1.1245)\tPrec @1 0.6875 (0.6113)\t\n",
            "Epoch: [1][440/1407]\tLoss 1.1823 (1.1245)\tPrec @1 0.5938 (0.6118)\t\n",
            "Epoch: [1][450/1407]\tLoss 1.3881 (1.1239)\tPrec @1 0.3438 (0.6112)\t\n",
            "Epoch: [1][460/1407]\tLoss 0.9244 (1.1223)\tPrec @1 0.7500 (0.6118)\t\n",
            "Epoch: [1][470/1407]\tLoss 0.9543 (1.1223)\tPrec @1 0.6875 (0.6118)\t\n",
            "Epoch: [1][480/1407]\tLoss 1.1328 (1.1222)\tPrec @1 0.6250 (0.6117)\t\n",
            "Epoch: [1][490/1407]\tLoss 0.9772 (1.1206)\tPrec @1 0.7188 (0.6127)\t\n",
            "Epoch: [1][500/1407]\tLoss 1.4545 (1.1208)\tPrec @1 0.5312 (0.6127)\t\n",
            "Epoch: [1][510/1407]\tLoss 1.1823 (1.1213)\tPrec @1 0.6250 (0.6132)\t\n",
            "Epoch: [1][520/1407]\tLoss 0.8827 (1.1208)\tPrec @1 0.6875 (0.6130)\t\n",
            "Epoch: [1][530/1407]\tLoss 1.2007 (1.1191)\tPrec @1 0.6875 (0.6136)\t\n",
            "Epoch: [1][540/1407]\tLoss 1.1670 (1.1194)\tPrec @1 0.7500 (0.6133)\t\n",
            "Epoch: [1][550/1407]\tLoss 1.1941 (1.1183)\tPrec @1 0.4688 (0.6137)\t\n",
            "Epoch: [1][560/1407]\tLoss 1.1323 (1.1161)\tPrec @1 0.5625 (0.6143)\t\n",
            "Epoch: [1][570/1407]\tLoss 1.0378 (1.1142)\tPrec @1 0.7188 (0.6155)\t\n",
            "Epoch: [1][580/1407]\tLoss 1.1314 (1.1125)\tPrec @1 0.5938 (0.6154)\t\n",
            "Epoch: [1][590/1407]\tLoss 1.2328 (1.1130)\tPrec @1 0.6562 (0.6156)\t\n",
            "Epoch: [1][600/1407]\tLoss 0.9204 (1.1125)\tPrec @1 0.7812 (0.6162)\t\n",
            "Epoch: [1][610/1407]\tLoss 1.0084 (1.1117)\tPrec @1 0.5625 (0.6163)\t\n",
            "Epoch: [1][620/1407]\tLoss 0.9814 (1.1105)\tPrec @1 0.6562 (0.6167)\t\n",
            "Epoch: [1][630/1407]\tLoss 1.1147 (1.1116)\tPrec @1 0.6250 (0.6163)\t\n",
            "Epoch: [1][640/1407]\tLoss 1.0942 (1.1114)\tPrec @1 0.6562 (0.6162)\t\n",
            "Epoch: [1][650/1407]\tLoss 1.2065 (1.1114)\tPrec @1 0.6250 (0.6164)\t\n",
            "Epoch: [1][660/1407]\tLoss 1.1230 (1.1102)\tPrec @1 0.6250 (0.6166)\t\n",
            "Epoch: [1][670/1407]\tLoss 1.2908 (1.1095)\tPrec @1 0.5312 (0.6173)\t\n",
            "Epoch: [1][680/1407]\tLoss 0.9648 (1.1102)\tPrec @1 0.6875 (0.6177)\t\n",
            "Epoch: [1][690/1407]\tLoss 1.3007 (1.1108)\tPrec @1 0.4062 (0.6176)\t\n",
            "Epoch: [1][700/1407]\tLoss 1.2500 (1.1107)\tPrec @1 0.4375 (0.6174)\t\n",
            "Epoch: [1][710/1407]\tLoss 1.4646 (1.1113)\tPrec @1 0.4688 (0.6171)\t\n",
            "Epoch: [1][720/1407]\tLoss 1.1137 (1.1099)\tPrec @1 0.5938 (0.6182)\t\n",
            "Epoch: [1][730/1407]\tLoss 1.3722 (1.1103)\tPrec @1 0.4688 (0.6180)\t\n",
            "Epoch: [1][740/1407]\tLoss 1.0348 (1.1107)\tPrec @1 0.6875 (0.6177)\t\n",
            "Epoch: [1][750/1407]\tLoss 0.9975 (1.1106)\tPrec @1 0.6562 (0.6178)\t\n",
            "Epoch: [1][760/1407]\tLoss 0.7672 (1.1097)\tPrec @1 0.8125 (0.6178)\t\n",
            "Epoch: [1][770/1407]\tLoss 0.8913 (1.1100)\tPrec @1 0.7188 (0.6179)\t\n",
            "Epoch: [1][780/1407]\tLoss 0.8613 (1.1091)\tPrec @1 0.7188 (0.6178)\t\n",
            "Epoch: [1][790/1407]\tLoss 1.2554 (1.1088)\tPrec @1 0.6562 (0.6182)\t\n",
            "Epoch: [1][800/1407]\tLoss 0.9793 (1.1084)\tPrec @1 0.6250 (0.6181)\t\n",
            "Epoch: [1][810/1407]\tLoss 1.0300 (1.1073)\tPrec @1 0.5312 (0.6183)\t\n",
            "Epoch: [1][820/1407]\tLoss 0.9972 (1.1068)\tPrec @1 0.6250 (0.6183)\t\n",
            "Epoch: [1][830/1407]\tLoss 1.0707 (1.1053)\tPrec @1 0.6562 (0.6189)\t\n",
            "Epoch: [1][840/1407]\tLoss 0.8697 (1.1055)\tPrec @1 0.6875 (0.6188)\t\n",
            "Epoch: [1][850/1407]\tLoss 0.9232 (1.1044)\tPrec @1 0.6562 (0.6190)\t\n",
            "Epoch: [1][860/1407]\tLoss 1.1632 (1.1048)\tPrec @1 0.6250 (0.6188)\t\n",
            "Epoch: [1][870/1407]\tLoss 1.0385 (1.1052)\tPrec @1 0.5938 (0.6186)\t\n",
            "Epoch: [1][880/1407]\tLoss 0.9579 (1.1044)\tPrec @1 0.6875 (0.6188)\t\n",
            "Epoch: [1][890/1407]\tLoss 1.0871 (1.1039)\tPrec @1 0.5938 (0.6191)\t\n",
            "Epoch: [1][900/1407]\tLoss 0.7120 (1.1028)\tPrec @1 0.8438 (0.6197)\t\n",
            "Epoch: [1][910/1407]\tLoss 1.2548 (1.1019)\tPrec @1 0.5312 (0.6202)\t\n",
            "Epoch: [1][920/1407]\tLoss 1.1435 (1.1010)\tPrec @1 0.6250 (0.6205)\t\n",
            "Epoch: [1][930/1407]\tLoss 1.1687 (1.1008)\tPrec @1 0.5625 (0.6204)\t\n",
            "Epoch: [1][940/1407]\tLoss 0.8452 (1.1008)\tPrec @1 0.7500 (0.6206)\t\n",
            "Epoch: [1][950/1407]\tLoss 0.9072 (1.1003)\tPrec @1 0.6250 (0.6208)\t\n",
            "Epoch: [1][960/1407]\tLoss 0.8854 (1.1004)\tPrec @1 0.7188 (0.6207)\t\n",
            "Epoch: [1][970/1407]\tLoss 1.0114 (1.1001)\tPrec @1 0.6250 (0.6209)\t\n",
            "Epoch: [1][980/1407]\tLoss 1.0201 (1.0996)\tPrec @1 0.6562 (0.6215)\t\n",
            "Epoch: [1][990/1407]\tLoss 0.9341 (1.0993)\tPrec @1 0.7500 (0.6215)\t\n",
            "Epoch: [1][1000/1407]\tLoss 1.2426 (1.0992)\tPrec @1 0.4688 (0.6216)\t\n",
            "Epoch: [1][1010/1407]\tLoss 0.9116 (1.0987)\tPrec @1 0.6875 (0.6219)\t\n",
            "Epoch: [1][1020/1407]\tLoss 0.9093 (1.0981)\tPrec @1 0.6562 (0.6218)\t\n",
            "Epoch: [1][1030/1407]\tLoss 1.1144 (1.0975)\tPrec @1 0.6250 (0.6222)\t\n",
            "Epoch: [1][1040/1407]\tLoss 1.0469 (1.0971)\tPrec @1 0.6250 (0.6224)\t\n",
            "Epoch: [1][1050/1407]\tLoss 1.0208 (1.0969)\tPrec @1 0.6875 (0.6224)\t\n",
            "Epoch: [1][1060/1407]\tLoss 0.9870 (1.0965)\tPrec @1 0.6250 (0.6223)\t\n",
            "Epoch: [1][1070/1407]\tLoss 1.0110 (1.0959)\tPrec @1 0.6250 (0.6226)\t\n",
            "Epoch: [1][1080/1407]\tLoss 1.1380 (1.0950)\tPrec @1 0.5312 (0.6225)\t\n",
            "Epoch: [1][1090/1407]\tLoss 1.0763 (1.0948)\tPrec @1 0.6250 (0.6225)\t\n",
            "Epoch: [1][1100/1407]\tLoss 1.4570 (1.0939)\tPrec @1 0.6250 (0.6230)\t\n",
            "Epoch: [1][1110/1407]\tLoss 0.8707 (1.0929)\tPrec @1 0.6562 (0.6234)\t\n",
            "Epoch: [1][1120/1407]\tLoss 1.0969 (1.0929)\tPrec @1 0.5938 (0.6233)\t\n",
            "Epoch: [1][1130/1407]\tLoss 1.0598 (1.0929)\tPrec @1 0.6562 (0.6232)\t\n",
            "Epoch: [1][1140/1407]\tLoss 0.7708 (1.0921)\tPrec @1 0.7812 (0.6234)\t\n",
            "Epoch: [1][1150/1407]\tLoss 1.1125 (1.0923)\tPrec @1 0.6250 (0.6234)\t\n",
            "Epoch: [1][1160/1407]\tLoss 1.1427 (1.0923)\tPrec @1 0.6562 (0.6236)\t\n",
            "Epoch: [1][1170/1407]\tLoss 0.8897 (1.0913)\tPrec @1 0.6875 (0.6241)\t\n",
            "Epoch: [1][1180/1407]\tLoss 1.1049 (1.0899)\tPrec @1 0.6875 (0.6246)\t\n",
            "Epoch: [1][1190/1407]\tLoss 1.1144 (1.0889)\tPrec @1 0.5625 (0.6250)\t\n",
            "Epoch: [1][1200/1407]\tLoss 1.3284 (1.0884)\tPrec @1 0.5625 (0.6252)\t\n",
            "Epoch: [1][1210/1407]\tLoss 0.8432 (1.0871)\tPrec @1 0.7188 (0.6256)\t\n",
            "Epoch: [1][1220/1407]\tLoss 0.9404 (1.0866)\tPrec @1 0.7500 (0.6256)\t\n",
            "Epoch: [1][1230/1407]\tLoss 0.8504 (1.0860)\tPrec @1 0.7500 (0.6261)\t\n",
            "Epoch: [1][1240/1407]\tLoss 0.9447 (1.0854)\tPrec @1 0.6250 (0.6264)\t\n",
            "Epoch: [1][1250/1407]\tLoss 1.0592 (1.0842)\tPrec @1 0.6562 (0.6270)\t\n",
            "Epoch: [1][1260/1407]\tLoss 0.9784 (1.0837)\tPrec @1 0.6562 (0.6272)\t\n",
            "Epoch: [1][1270/1407]\tLoss 0.9634 (1.0824)\tPrec @1 0.6562 (0.6277)\t\n",
            "Epoch: [1][1280/1407]\tLoss 0.9863 (1.0817)\tPrec @1 0.6875 (0.6279)\t\n",
            "Epoch: [1][1290/1407]\tLoss 1.1847 (1.0813)\tPrec @1 0.6250 (0.6279)\t\n",
            "Epoch: [1][1300/1407]\tLoss 0.8349 (1.0808)\tPrec @1 0.7812 (0.6281)\t\n",
            "Epoch: [1][1310/1407]\tLoss 0.8179 (1.0796)\tPrec @1 0.7812 (0.6284)\t\n",
            "Epoch: [1][1320/1407]\tLoss 1.0283 (1.0791)\tPrec @1 0.6562 (0.6287)\t\n",
            "Epoch: [1][1330/1407]\tLoss 1.2006 (1.0786)\tPrec @1 0.5312 (0.6288)\t\n",
            "Epoch: [1][1340/1407]\tLoss 0.8638 (1.0783)\tPrec @1 0.7500 (0.6291)\t\n",
            "Epoch: [1][1350/1407]\tLoss 1.0164 (1.0783)\tPrec @1 0.5625 (0.6291)\t\n",
            "Epoch: [1][1360/1407]\tLoss 0.9607 (1.0781)\tPrec @1 0.6562 (0.6292)\t\n",
            "Epoch: [1][1370/1407]\tLoss 0.9305 (1.0767)\tPrec @1 0.6875 (0.6300)\t\n",
            "Epoch: [1][1380/1407]\tLoss 1.3037 (1.0766)\tPrec @1 0.5312 (0.6299)\t\n",
            "Epoch: [1][1390/1407]\tLoss 1.2903 (1.0759)\tPrec @1 0.5938 (0.6304)\t\n",
            "Epoch: [1][1400/1407]\tLoss 0.7672 (1.0751)\tPrec @1 0.7500 (0.6306)\t\n",
            "Epoch 1 | Training accuracy: 0.6305333375930786% | Validation accuracy: 0.6150000095367432%\n",
            "Epoch: [2][0/1407]\tLoss 0.9003 (0.9003)\tPrec @1 0.6250 (0.6250)\t\n",
            "Epoch: [2][10/1407]\tLoss 0.9398 (0.8968)\tPrec @1 0.7188 (0.6761)\t\n",
            "Epoch: [2][20/1407]\tLoss 0.8805 (0.9347)\tPrec @1 0.6875 (0.6741)\t\n",
            "Epoch: [2][30/1407]\tLoss 0.8639 (0.9457)\tPrec @1 0.7188 (0.6835)\t\n",
            "Epoch: [2][40/1407]\tLoss 1.1869 (0.9623)\tPrec @1 0.5625 (0.6814)\t\n",
            "Epoch: [2][50/1407]\tLoss 0.7266 (0.9691)\tPrec @1 0.8125 (0.6752)\t\n",
            "Epoch: [2][60/1407]\tLoss 0.8645 (0.9586)\tPrec @1 0.6875 (0.6778)\t\n",
            "Epoch: [2][70/1407]\tLoss 0.8552 (0.9578)\tPrec @1 0.7500 (0.6787)\t\n",
            "Epoch: [2][80/1407]\tLoss 1.2029 (0.9644)\tPrec @1 0.6250 (0.6759)\t\n",
            "Epoch: [2][90/1407]\tLoss 1.0279 (0.9709)\tPrec @1 0.5938 (0.6720)\t\n",
            "Epoch: [2][100/1407]\tLoss 0.8215 (0.9740)\tPrec @1 0.6562 (0.6699)\t\n",
            "Epoch: [2][110/1407]\tLoss 0.9158 (0.9731)\tPrec @1 0.7500 (0.6695)\t\n",
            "Epoch: [2][120/1407]\tLoss 0.7651 (0.9741)\tPrec @1 0.7500 (0.6699)\t\n",
            "Epoch: [2][130/1407]\tLoss 0.7851 (0.9682)\tPrec @1 0.7188 (0.6715)\t\n",
            "Epoch: [2][140/1407]\tLoss 1.0368 (0.9759)\tPrec @1 0.5625 (0.6682)\t\n",
            "Epoch: [2][150/1407]\tLoss 1.0250 (0.9758)\tPrec @1 0.5938 (0.6666)\t\n",
            "Epoch: [2][160/1407]\tLoss 0.9342 (0.9762)\tPrec @1 0.7812 (0.6671)\t\n",
            "Epoch: [2][170/1407]\tLoss 1.0120 (0.9774)\tPrec @1 0.6562 (0.6663)\t\n",
            "Epoch: [2][180/1407]\tLoss 1.1916 (0.9760)\tPrec @1 0.6250 (0.6676)\t\n",
            "Epoch: [2][190/1407]\tLoss 0.9605 (0.9691)\tPrec @1 0.5938 (0.6702)\t\n",
            "Epoch: [2][200/1407]\tLoss 1.1447 (0.9705)\tPrec @1 0.6875 (0.6698)\t\n",
            "Epoch: [2][210/1407]\tLoss 1.4170 (0.9738)\tPrec @1 0.5000 (0.6685)\t\n",
            "Epoch: [2][220/1407]\tLoss 1.2880 (0.9778)\tPrec @1 0.5000 (0.6673)\t\n",
            "Epoch: [2][230/1407]\tLoss 0.8798 (0.9823)\tPrec @1 0.6562 (0.6659)\t\n",
            "Epoch: [2][240/1407]\tLoss 0.7459 (0.9780)\tPrec @1 0.7188 (0.6668)\t\n",
            "Epoch: [2][250/1407]\tLoss 0.8869 (0.9767)\tPrec @1 0.7812 (0.6680)\t\n",
            "Epoch: [2][260/1407]\tLoss 0.9637 (0.9734)\tPrec @1 0.6562 (0.6687)\t\n",
            "Epoch: [2][270/1407]\tLoss 1.0674 (0.9751)\tPrec @1 0.5000 (0.6670)\t\n",
            "Epoch: [2][280/1407]\tLoss 0.6839 (0.9712)\tPrec @1 0.8125 (0.6685)\t\n",
            "Epoch: [2][290/1407]\tLoss 1.0012 (0.9688)\tPrec @1 0.7500 (0.6698)\t\n",
            "Epoch: [2][300/1407]\tLoss 1.0527 (0.9703)\tPrec @1 0.7500 (0.6699)\t\n",
            "Epoch: [2][310/1407]\tLoss 0.8206 (0.9698)\tPrec @1 0.7812 (0.6700)\t\n",
            "Epoch: [2][320/1407]\tLoss 0.9541 (0.9688)\tPrec @1 0.7500 (0.6706)\t\n",
            "Epoch: [2][330/1407]\tLoss 0.7700 (0.9670)\tPrec @1 0.7500 (0.6704)\t\n",
            "Epoch: [2][340/1407]\tLoss 0.8132 (0.9681)\tPrec @1 0.6875 (0.6705)\t\n",
            "Epoch: [2][350/1407]\tLoss 0.9320 (0.9672)\tPrec @1 0.6875 (0.6710)\t\n",
            "Epoch: [2][360/1407]\tLoss 1.0102 (0.9684)\tPrec @1 0.6250 (0.6707)\t\n",
            "Epoch: [2][370/1407]\tLoss 1.0517 (0.9702)\tPrec @1 0.7500 (0.6706)\t\n",
            "Epoch: [2][380/1407]\tLoss 0.9049 (0.9708)\tPrec @1 0.6562 (0.6695)\t\n",
            "Epoch: [2][390/1407]\tLoss 0.9990 (0.9701)\tPrec @1 0.6562 (0.6698)\t\n",
            "Epoch: [2][400/1407]\tLoss 1.3616 (0.9712)\tPrec @1 0.5938 (0.6702)\t\n",
            "Epoch: [2][410/1407]\tLoss 0.9043 (0.9704)\tPrec @1 0.6250 (0.6705)\t\n",
            "Epoch: [2][420/1407]\tLoss 0.8080 (0.9712)\tPrec @1 0.7812 (0.6700)\t\n",
            "Epoch: [2][430/1407]\tLoss 0.7071 (0.9692)\tPrec @1 0.6875 (0.6707)\t\n",
            "Epoch: [2][440/1407]\tLoss 0.9776 (0.9695)\tPrec @1 0.6875 (0.6711)\t\n",
            "Epoch: [2][450/1407]\tLoss 1.2082 (0.9691)\tPrec @1 0.5312 (0.6707)\t\n",
            "Epoch: [2][460/1407]\tLoss 0.7502 (0.9677)\tPrec @1 0.7812 (0.6713)\t\n",
            "Epoch: [2][470/1407]\tLoss 0.7837 (0.9678)\tPrec @1 0.7188 (0.6713)\t\n",
            "Epoch: [2][480/1407]\tLoss 1.0924 (0.9685)\tPrec @1 0.6562 (0.6708)\t\n",
            "Epoch: [2][490/1407]\tLoss 0.7973 (0.9670)\tPrec @1 0.7812 (0.6718)\t\n",
            "Epoch: [2][500/1407]\tLoss 1.2835 (0.9672)\tPrec @1 0.5625 (0.6717)\t\n",
            "Epoch: [2][510/1407]\tLoss 1.1235 (0.9679)\tPrec @1 0.6562 (0.6721)\t\n",
            "Epoch: [2][520/1407]\tLoss 0.7960 (0.9677)\tPrec @1 0.6875 (0.6719)\t\n",
            "Epoch: [2][530/1407]\tLoss 1.0593 (0.9664)\tPrec @1 0.6562 (0.6721)\t\n",
            "Epoch: [2][540/1407]\tLoss 1.0564 (0.9669)\tPrec @1 0.7500 (0.6719)\t\n",
            "Epoch: [2][550/1407]\tLoss 1.0266 (0.9655)\tPrec @1 0.5938 (0.6725)\t\n",
            "Epoch: [2][560/1407]\tLoss 0.9865 (0.9640)\tPrec @1 0.6875 (0.6728)\t\n",
            "Epoch: [2][570/1407]\tLoss 0.9170 (0.9625)\tPrec @1 0.7500 (0.6737)\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fc2076647911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mvalidation_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_accuracy_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/team36/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMiKV7SObRGI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}